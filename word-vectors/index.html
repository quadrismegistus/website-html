<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <style type='text/css'>
        body {
            font-family:'Baskerville', 'Libre Baskerville','Courier New', Courier, monospace;
            /* text-align:center; */
            /* font-size:1.1em; */
            line-height: 1.5em;
        }
        img {
            display: block;
            margin: 0 auto;
            width: 200px;
        }
        h1 { text-align: center;}
        #content {
            max-width:600px;
            margin: 0 auto;
        }
    
        p { text-align: justify }
        li {
        margin: 0;
        padding: 0;
        line-height:1em;
    }
    
        </style>
    <title>Ryan Heuser</title>
</head>
<body>
    <div id="content">
        <h1 id="word-vectors-in-the-eighteenth-century">Word Vectors in the Eighteenth Century</h1>
<h2 id="word-vectors">Word Vectors</h2>
<p>This page is meant as a set of links and resources related to my work using word vectors to study eighteenth-century literature. This work asks the question: how can new vector-based models of semantics reveal the historicity of specific configurations of meaning in eighteenth-century literature? Most of this work is published serially as blog posts, linked below. The later of these are “slideshow essays”-experiments with the forms of visual rhetoric that work so well in the digital humanities-rather than traditional blog posts. There is also a video of a talk I’ve given about this work. Lastly, I’ve uploaded several word2vec models I’m using, trained on a corpus of eighteenth-century literature; and linked to some relevant code (more code will be coming soon).</p>
<h3 id="posts">Posts</h3>
<ul>
<li><a href="/word-vectors-1">Episode 1: Concepts</a> (14 Apr 2016)</li>
<li><a href="/word-vectors-2">Episode 2: Methods</a> (1 Jun 2016)</li>
<li><a href="/word-vectors-3">Episode 3: From Fields to Vectors</a> (10 Sep 2016)</li>
<li><a href="/word-vectors-4">Episode 4: Semantic Networks</a> (25 Sep 2016)</li>
</ul>
<h3 id="video">Video</h3>
<ul>
<li><a href="http://helper.ipam.ucla.edu/wowzavideo.aspx?vfn=13284_480.mp4&amp;vfd=CA2016">Presentation at IPAM in UCLA</a> (25 May 2016)</li>
</ul>
<h3 id="appendices">Appendices</h3>
<ul>
<li>“<a href="/word2vec-vs-the-mat">Would Word2Vec get into grad school? Evaluating Word2Vec against the Miller Analogies Test</a>”</li>
</ul>
<h3 id="models">Models</h3>
<ul>
<li><a href="https://archive.org/details/word-vectors-18c-word2vec-models-across-20-year-periods">Word2Vec Models for Twenty-year Periods of 18C (ECCO, “Literature and Language,” 1700-99)</a> (150 million words each; skip-gram size of 10 words)</li>
</ul>
<h3 id="code">Code</h3>
<ul>
<li><a href="/word2vec-vs-the-mat#code">Code to evaluate a word2vec model against the Miller Analogies Test</a></li>
<li><a href="https://gist.github.com/quadrismegistus/eb2360026afce4ef4e57872146369091">Code to produce a semantic network from a gensim word2vec model</a></li>
<li><a href="https://gist.github.com/quadrismegistus/09a93e219a6ffc4f216fb85235535faf">Code for aligning two gensim word2vec models using Procrustes matrix alignment</a></li>
</ul>

    </div>
</body>

</html>